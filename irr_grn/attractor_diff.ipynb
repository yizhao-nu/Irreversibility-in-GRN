{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "np.set_printoptions(threshold=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the frequency of each attractor period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_param_l = [0.2,0.4,0.6,0.8]\n",
    "param_pairs = [(1,0),(0,1)] + [(0,ss) for ss in sel_param_l] + [(ss,1-ss) for ss in sel_param_l] + [(ss,1) for ss in sel_param_l]\n",
    "oords = ['asc','desc']\n",
    "att_d = {}\n",
    "att_sizes_d = {}\n",
    "#num_unchanged = []\n",
    "#unchanged = []\n",
    "for rep in range(20):\n",
    "    for ss,rr in param_pairs:\n",
    "        for oord in oords:\n",
    "            if ((ss,rr)!=(0,0)) and ((ss,rr)!=(0,1)):\n",
    "                attfn = 'attfiles/att_twoparam_%.2f_%.2f_%s_%02d_%d.txt' %(ss,rr,oord,rep,rep)\n",
    "            elif (ss,rr)==(1,0):\n",
    "                attfn = 'attfiles/att_twoparam_1.00_0.00_desc_00_0.txt'\n",
    "            elif (ss,rr)==(0,1):\n",
    "                attfn = 'attfiles/att_twoparam_0.00_1.00_desc_00_0.txt'\n",
    "            if not osp.exists(attfn):\n",
    "                continue\n",
    "            with open(attfn,encoding='utf-8') as fo:\n",
    "                lines=fo.readlines()\n",
    "            for i,line in enumerate(lines):\n",
    "                if line.startswith('Attractor number:'):\n",
    "                    att_no = int(line.split(':')[1].split(' ')[0])\n",
    "                    att_size = int(line.split(':')[-1].strip())\n",
    "                    att_sizes_d[(oord,ss,rr,rep,att_no)]=att_size\n",
    "                    if att_size != 1:\n",
    "                        att = []\n",
    "                        for k in range(1,att_size+1):\n",
    "                            state = lines[i-k].strip()\n",
    "                            att.append(state)\n",
    "                        att_str = ' '.join(att)\n",
    "                        att_d[(oord,ss,rr,rep,att_no)]=att_str\n",
    "att_sizes_ser = pd.Series(att_sizes_d)\n",
    "att_ser = pd.Series(att_d)\n",
    "att_ser.to_pickle('att_ser.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency of each attractor period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_freq_ser = att_sizes_ser.value_counts(normalize=True).sort_index()\n",
    "attr_freq_ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attr_stats(anum,sattr,attrsize):\n",
    "    sattr1 = np.asarray([[int(elt) for elt in bstr] for bstr in sattr.split(' ')])\n",
    "    HH = [np.sum(np.abs(sattr1[(jj+1)%attrsize]-sattr1[jj])) for jj in range(attrsize)]\n",
    "    ss = np.sum(sattr1,axis=0)\n",
    "    cnodes = np.where((ss>0)&(ss<attrsize))[0]\n",
    "    return anum,cnodes,HH\n",
    "\n",
    "att_ser = pd.Series(att_d)\n",
    "hamming_steps2 = {}\n",
    "changing_nodes2 = {}\n",
    "changing_node_sets2 = {}\n",
    "for (order,ss,rr,rep),nonfpcnt in periodic_attrcounts.items():\n",
    "    print('--->',order,ss,rr,rep)\n",
    "    sel_attrs = att_ser.xs((order,ss,rr,rep),level=[0,1,2,3])\n",
    "    for anum,sattr in sel_attrs.items():\n",
    "        attrsize = len(sattr.split(' '))\n",
    "        anum,cnds,HH = get_attr_stats(anum,sattr,attrsize)\n",
    "        hamming_steps2[(order,ss,rr,rep,anum)]=HH\n",
    "        changing_nodes2[(order,ss,rr,rep,anum)]=cnds\n",
    "\n",
    "for ii,nd_l in changing_nodes2.items():\n",
    "    changing_node_sets2[ii]=' '.join(['%d' % nd for nd in nd_l])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency of preservation under asynchronous dynamics of each attractor period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### determination of attractors with db0\n",
    "gn_tup_has_0dB0 = {}\n",
    "preservation_freq_d = {}\n",
    "for att_len,att_freq in att_sizes_ser.value_counts(normalize=True).items():\n",
    "    if att_len==1:\n",
    "        continue\n",
    "    #print(att_len)\n",
    "    periodx_d = {}\n",
    "    for (srt, ss, rr, rep, attno)  in att_sizes_ser[att_sizes_ser==att_len].index:\n",
    "        sattr = att_d[(srt, ss, rr, rep, attno)]\n",
    "        attno,cnds,HH = get_attr_stats(attno,sattr,att_len)\n",
    "        #sarr = np.asarray([[int(elt) for elt in bstr] for bstr in sattr.split(' ')])\n",
    "        periodx_d[(srt, ss, rr, rep, attno)] = tuple(sorted([nodes[ii] for ii in cnds]))\n",
    "    periodx_vcs = pd.Series(periodx_d).value_counts()\n",
    "    #print(f'Period {att_len} value counts determined')\n",
    "    tot_db0 = 0\n",
    "    for gn_tup,numattr in periodx_vcs.items():\n",
    "        dB0 = set([])\n",
    "        for (gn1,gn2) in combs(gn_tup,2):\n",
    "            dB0 |= set(list(G_rs2.successors(gn1)))&set(list(G_rs2.successors(gn2)))\n",
    "        if len(set(dB0)-set(gn_tup))==0:\n",
    "            tot_db0 +=numattr\n",
    "            gn_tup_has_0dB0[tuple(sorted(list(gn_tup)))]=True\n",
    "        else:\n",
    "            gn_tup_has_0dB0[tuple(sorted(list(gn_tup)))]=False\n",
    "    print(f'Period: {att_len}\\t Frequency: {(tot_db0/periodx_vcs.sum()):.04f}')\n",
    "    preservation_freq_d[att_len]=tot_db0/periodx_vcs.sum()\n",
    "preservation_freq_ser = pd.Series(preservation_freq_d)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall rate of attractor preservation under asynchronous dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((attr_freq_ser*preservation_freq_ser).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preservation of initial and final attractors for partial fixed points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr_ss_l = [(0.2,0.8),(0.8,0),(0.6,0),(0.4,0),(0.2,0),\n",
    "           (1,0),(1,0.2),(1,0.4),(1,0.6),(1,0.8),\n",
    "           (0.8,0.2),(0.6,0.4),(0.4,0.6),(0,1)]\n",
    "stats_d = {}\n",
    "pfp2fp_d = {}\n",
    "pfp2fp_pres_d = {}\n",
    "fp2pfp_d = {}\n",
    "fp2pfp_pres_d = {}\n",
    "pfp2pfp_d = {}\n",
    "tot_pres = 0\n",
    "tot_pfp_trans = 0\n",
    "for srt in ['asc','desc']:\n",
    "    print(srt)\n",
    "    for (rr,ss) in rr_ss_l:\n",
    "        print(rr,ss)\n",
    "        ii_vals = range(20) if not (ss,rr) in [(0,1),(1,0),(1,1),(0,0)] else [0]\n",
    "        for ii in ii_vals:\n",
    "            print(ii)\n",
    "            for pt in ['KO','OE']:\n",
    "                fn = f'results/result-attr-trans-{pt}-twoparam_{ss:.02f}_{rr:.02f}_{srt}_{ii:02d}_{ii}.csv'\n",
    "                kw_tup = (srt,ss,rr,ii,pt)\n",
    "                row_d = {}\n",
    "                try:\n",
    "                    RES2 = pd.read_csv(fn)\n",
    "                except FileNotFoundError:\n",
    "                    print(\"missing file\",fn)\n",
    "                    continue\n",
    "                cX = (RES2.init_attr_index==RES2.fin_attr_index)\n",
    "                row_d['total_trans'] = cX.shape[0]\n",
    "                row_d['not_act_irrev'] = cX.sum()\n",
    "                RES = RES2[~cX]\n",
    "                condA  = (RES.init_num_fixed==RES.fin_num_fixed) ## no. time-dependent nodes equal before/after\n",
    "                condB = (RES.init_num_fixed>0) ## no. time-dependent nodes greater than 0 in initial attr\n",
    "                condC = (RES.fin_num_fixed>0) ## no. time-dependent nodes greater than 0 in initial attr\n",
    "                condD = (RES.num_fixed_changed>0) ## no. time-independent nodes that change between attractors\n",
    "                pfp_trans = RES[(condA) & (condB)] ## partial fixed point attractors\n",
    "                row_d['eq_attrsize']=pfp_trans.shape[0]\n",
    "                pfp_trans_fixed = RES[(condA) & (condB)] ## transitions between PFPs w/ fixed part changed only\n",
    "                row_d['eq_attrsize_fixonly']=pfp_trans_fixed.is_fixed_changed.sum()\n",
    "                fp_trans = RES[(condA) & (~condB)] ## transitions between FPs\n",
    "                row_d['fp_trans']=fp_trans.shape[0]\n",
    "                fp2pfp_trans = RES[(~condA) & (condB&~condC)] ## transition FP -> PFP, look at the genes responsible\n",
    "                fp2pfp_perts = fp2pfp_trans.pert_gene_name.value_counts()\n",
    "                fp2pfp_d[kw_tup] = fp2pfp_perts\n",
    "                fp2pfp_trans_pres = RES[(~condA) & (condB&~condC)&(condD)] ## transition FP -> PFP, look at the genes responsible\n",
    "                fp2pfp_perts_pres = fp2pfp_trans_pres.pert_gene_name.value_counts()\n",
    "                fp2pfp_pres_d[kw_tup] = fp2pfp_perts_pres\n",
    "                pfp2fp_trans = RES[(~condA) & (~condB&condC)] ## transition PFP -> FP, look at the genes responsible\n",
    "                pfp2fp_perts = pfp2fp_trans.pert_gene_name.value_counts()\n",
    "                pfp2fp_d[kw_tup]=pfp2fp_perts\n",
    "                pfp2fp_trans_pres = RES[(~condA) & (~condB&condC)&(condD)] ## transition PFP -> FP, look at the genes responsible\n",
    "                pfp2fp_perts_pres = pfp2fp_trans_pres.pert_gene_name.value_counts()\n",
    "                pfp2fp_pres_d[kw_tup]=pfp2fp_perts_pres\n",
    "                pfp_trans_diff = RES[(~condA) & (condB & condC)] ## transitions between PFPs with different periods\n",
    "                pfp2pfp_perts = pfp_trans_diff.pert_gene_name.value_counts()\n",
    "                pfp2pfp_d[kw_tup]=pfp2pfp_perts\n",
    "                row_d['pfp_neq_periods']=pfp_trans_diff.shape[0]\n",
    "                for kk,vv in row_d.items():\n",
    "                    stats_d[tuple(list(kw_tup)+[kk])]=vv\n",
    "                \n",
    "                \n",
    "                pfp_vcs = pfp_trans.loc[:,['init_attr_index','fin_attr_index']].value_counts()\n",
    "                for (iai,fai),tcnt in pfp_vcs.items():\n",
    "                    tot_pfp_trans+=tcnt\n",
    "                    iattr = att_ser.loc[(srt,ss,rr,ii,iai)]\n",
    "                    iattrsize = len(iattr.split(' '))\n",
    "                    iai,icnds,iHH = get_attr_stats(iai,iattr,iattrsize)\n",
    "                    ign_tup = tuple(sorted([nodes[icnd] for icnd in icnds]))\n",
    "                    if ign_tup in gn_tup_has_0dB0.keys():\n",
    "                        iTF = gn_tup_has_0dB0[ign_tup]\n",
    "                    else:\n",
    "                        if iattrsize in [2,4]:\n",
    "                            print(ign_tup)\n",
    "                        iTF = False\n",
    "                    fattr = att_ser.loc[(srt,ss,rr,ii,fai)]\n",
    "                    fattrsize = len(fattr.split(' '))\n",
    "                    fai,fcnds,fHH = get_attr_stats(fai,fattr,fattrsize)\n",
    "                    fgn_tup = tuple(sorted([nodes[fcnd] for fcnd in fcnds]))\n",
    "                    if fgn_tup in gn_tup_has_0dB0.keys():\n",
    "                        fTF = gn_tup_has_0dB0[fgn_tup]\n",
    "                    else:\n",
    "                        if fattrsize in [2,4]:\n",
    "                            print(fgn_tup)\n",
    "                            break\n",
    "                        fTF = False\n",
    "                    if iTF and fTF: ## both initial and final pfps are preserved\n",
    "                        tot_pres+=tcnt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rate of preseravation of transitions between pfps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tot_pres/tot_pfp_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = pd.Series(stats_d).unstack()\n",
    "stats_df2 = stats_df.groupby(level=[0,1,2]).sum()\n",
    "tofromfp_d = {}\n",
    "for kk,vv in pfp2fp_d.items():\n",
    "    if kk in fp2pfp_d.keys():\n",
    "        tofromfp_d[kk] = ((fp2pfp_d[kk].sum()+vv.sum())/stats_df.loc[kk,'total_trans'])\n",
    "    else:\n",
    "        tofromfp_d[kk] = vv.sum()/stats_df.loc[kk,'total_trans']\n",
    "for kk in set(fp2pfp_d.keys())-set(pfp2fp_d.keys()):\n",
    "    tofromfp_d[kk] = fp2pfp_d[kk].sum()/stats_df.loc[kk,'total_trans']\n",
    "## Number of transitions in which only one is a fixed point    \n",
    "pd.Series(tofromfp_d).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfp2fp_d2 = dict(filter(lambda kk: kk[1].shape[0]>0,pfp2fp_d.items()))\n",
    "fp2pfp_d2 = dict(filter(lambda kk: kk[1].shape[0]>0,fp2pfp_d.items()))\n",
    "pfp2fp_pres_d2 = dict(filter(lambda kk: kk[1].shape[0]>0,pfp2fp_pres_d.items()))\n",
    "fp2pfp_pres_d2 = dict(filter(lambda kk: kk[1].shape[0]>0,fp2pfp_pres_d.items()))\n",
    "\n",
    "tmp_d ={}\n",
    "for ind,row in stats_df2.iterrows():\n",
    "    A = row.loc['fp_trans']/row.loc['total_trans']\n",
    "    B = row.loc['eq_attrsize_fixonly']/row.loc['total_trans']\n",
    "    pfp2fp_keys = [kk for kk in pfp2fp_d2.keys() if all([ind[ii]==kk[ii] for ii in range(3)])]\n",
    "    fp2pfp_keys = [kk for kk in fp2pfp_d2.keys() if all([ind[ii]==kk[ii] for ii in range(3)])]\n",
    "    stats_df_keys = [kk for kk in stats_df.index if all([ind[ii]==kk[ii] for ii in range(3)])]\n",
    "    C_l = []\n",
    "    for kk in list(set(stats_df_keys)):\n",
    "        if kk in pfp2fp_keys and kk in fp2pfp_keys:\n",
    "            CC = (pfp2fp_d2[kk].sum()+fp2pfp_d2[kk].sum())/stats_df.loc[kk,'total_trans']\n",
    "        elif kk in pfp2fp_keys:\n",
    "            CC = pfp2fp_d2[kk].sum()/stats_df.loc[kk,'total_trans']\n",
    "        elif kk in fp2pfp_keys:\n",
    "            CC = fp2pfp_d2[kk].sum()/stats_df.loc[kk,'total_trans']\n",
    "        else:\n",
    "            CC = 0\n",
    "        C_l.append(CC)\n",
    "    C = np.mean(C_l)\n",
    "    pfp2fp_pres_keys = [kk for kk in pfp2fp_pres_d2.keys() if all([ind[ii]==kk[ii] for ii in range(3)])]\n",
    "    fp2pfp_pres_keys = [kk for kk in fp2pfp_pres_d2.keys() if all([ind[ii]==kk[ii] for ii in range(3)])]\n",
    "    stats_pres_df_keys = [kk for kk in stats_df.index if all([ind[ii]==kk[ii] for ii in range(3)])]\n",
    "    D_l = []\n",
    "    for kk in list(set(stats_pres_df_keys)):\n",
    "        if kk in pfp2fp_pres_keys and kk in fp2pfp_pres_keys:\n",
    "            DD = (pfp2fp_pres_d2[kk].sum()+fp2pfp_pres_d2[kk].sum())/stats_df.loc[kk,'total_trans']\n",
    "        elif kk in pfp2fp_pres_keys:\n",
    "            DD = pfp2fp_pres_d2[kk].sum()/stats_df.loc[kk,'total_trans']\n",
    "        elif kk in fp2pfp_pres_keys:\n",
    "            DD = fp2pfp_pres_d2[kk].sum()/stats_df.loc[kk,'total_trans']\n",
    "        else:\n",
    "            DD = 0\n",
    "        D_l.append(DD)\n",
    "    D = np.mean(D_l)\n",
    "    tmp_d[tuple(list(ind)+['fp'])]=A\n",
    "    tmp_d[tuple(list(ind)+['pfp'])]=B\n",
    "    tmp_d[tuple(list(ind)+['tofromfp'])]=C\n",
    "    tmp_d[tuple(list(ind)+['tofromfp_pres'])]=D\n",
    "## Fraction of transitions of each type, including those that are preserved\n",
    "transition_stats = pd.Series(tmp_d).unstack().mean()\n",
    "transition_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rate of preserved attractors (transition types are taken from the table above)\n",
    "transition_stats.loc['fp'] + transition_stats.loc['pfp'] * tot_pres/tot_pfp_trans + transition_stats.loc['tofromfp_pres']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "de3a0d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import patsy\n",
    "import networkx as nx\n",
    "from networkx.readwrite.graphml import read_graphml\n",
    "from networkx.algorithms.shortest_paths.generic import shortest_path_length\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib.colors import ListedColormap\n",
    "plt.rcParams['svg.fonttype']='none'\n",
    "plt.rcParams['text.usetex']=False\n",
    "plt.rcParams['font.family']='sans'\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3d57dc-2408-4358-9dd0-a1cb93907f6f",
   "metadata": {},
   "source": [
    "## Gather results for different scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "394681ae-7a03-497e-bf28-519a09f56a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "## a more streamlined implementation of the function in the attractors script\n",
    "def attractors_1state_from_txt(txt_name, network_name, cleanup=True):\n",
    "    with open(network_name+'.bnet',encoding='utf-8') as fo:\n",
    "        nodes_bnet = [ln.strip().split(',')[0] for ln in fo]\n",
    "    with open(network_name+'.cnet',encoding='utf-8') as fo:\n",
    "        ln0=fo.readline()\n",
    "    ln0 = ln0.replace('\\n', \"\").replace('#', \"\").strip()\n",
    "    nodes_cnet = ln0.split(', ')\n",
    "    idx = pd.Series(dict([(vv,kk) for kk,vv in enumerate(nodes_cnet)])).loc[nodes_bnet]\n",
    "    attractors = list()\n",
    "    with open(txt_name,encoding='utf-8') as fo:\n",
    "        p=fo.readlines()\n",
    "    current_attractor = []\n",
    "    sizes = []\n",
    "    for line in p[1:]:\n",
    "        # Strip line\n",
    "        cleanline = line.strip().replace('\\n', \"\")\n",
    "        #print(\"{:d}: '{:s}'\".format(i ,cleanline))\n",
    "        if cleanline.startswith('Attractor'):\n",
    "            attractors.append(current_attractor[0])\n",
    "            current_attractor = []\n",
    "            size = cleanline[-1]            \n",
    "            sizes.append(size)\n",
    "        elif 'average' in cleanline:\n",
    "            pass\n",
    "        elif len(cleanline) > 0 and cleanline.startswith(('0','1')):\n",
    "            cleanline = np.array([int(elt) for elt in cleanline])\n",
    "            current_attractor.append(cleanline)\n",
    "    attractors = np.c_[attractors].astype(int)[:,idx.values]\n",
    "    return pd.DataFrame(attractors,columns=idx.index,index=range(1,attractors.shape[0]+1))\n",
    "    #np.savetxt('./attfiles/1st_%s.csv' % (network_name.split('/')[-1]), attractors, delimiter = ',') \n",
    "    #return attractors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1448fd87-820f-4516-aad1-f069099f09a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "irrev_d = {}\n",
    "avgstate_d = {}\n",
    "numattr_d = {}\n",
    "for aa,pt in enumerate(['KO','OE']):\n",
    "    for bb,srt in enumerate(['desc','asc']):\n",
    "        fn_l = glob(\"results/result-%s-twoparam_*_*_%s_*.csv\" % (pt,srt))\n",
    "        for fn in fn_l:\n",
    "            __,ss,rr,__,rep,__ = fn.split('/')[-1].split('_')\n",
    "            att_fn = \"attfiles/1st_twoparam_%s_%s_%s_%s_%d.csv\" % (ss,rr,srt,rep,int(rep))\n",
    "            if not osp.exists(att_fn):\n",
    "                print('missing',att_fn)\n",
    "                continue\n",
    "            attractors_df = pd.read_csv(att_fn,header=None)\n",
    "            if srt == 'asc':\n",
    "                attractors_df.columns = asc_l\n",
    "            else:\n",
    "                attractors_df.columns = desc_l\n",
    "            attractors_df.index = [elt for elt in range(1,attractors_df.shape[0]+1)]\n",
    "            results = pd.read_csv(\"results/result-%s-twoparam_%s_%s_%s_%s_%d-pre.csv\" % (pt,ss,rr,srt,rep,int(rep)),index_col=0)\n",
    "            results = results.iloc[:-2]\n",
    "            if attractors_df.shape[0]==results.shape[0]:\n",
    "                results = results.loc[attractors_df.index]\n",
    "            irrev_d[(srt,pt,ss,rr,rep)] = results.mean(axis=0) ## the mean is taken across attractors\n",
    "            if pt=='KO': ## this does not depend on the perturbation type\n",
    "                avgstate_d[(srt,ss,rr,rep)] = attractors_df.loc[results.index].mean(axis=0)\n",
    "                numattr_d[(srt,ss,rr,rep)] = attractors_df.shape[0]\n",
    "\n",
    "DF = pd.DataFrame(irrev_d.keys())\n",
    "## unit test to confirm that the attractors match \n",
    "##     for knockouts, everywhere that there is a \"0\" in the attractor with have an NaN entry in the irreversibility\n",
    "for nn,row in results.loc[:257,attractors_df.columns].iterrows():\n",
    "    if nn>256:\n",
    "        continue\n",
    "    inds1 = np.where(row.isna())[0]\n",
    "    inds2 = np.where(attractors_df.loc[nn]==0)[0]\n",
    "    if not np.all(inds1==inds2):\n",
    "        break\n",
    "else:\n",
    "    print(\"Test passed\")\n",
    "\n",
    "ppairs_l = []\n",
    "for kk in irrev_d.keys():\n",
    "    ppairs_l.append((kk[-3],kk[-2]))\n",
    "\n",
    "ens_avg_irrev = {}\n",
    "ens_avg_state = {}\n",
    "ens_avg_nattr = {}\n",
    "for (rr,ss) in set(ppairs_l):\n",
    "    print(rr,ss)\n",
    "    for srt in ['asc','desc']:\n",
    "        print(srt)\n",
    "        sel_keys = [kk for kk in irrev_d.keys() if kk[0]==srt and kk[1]=='KO' and kk[2]==rr and kk[3]==ss]\n",
    "        rep_irrev_d = {}\n",
    "        rep_state_d = {}\n",
    "        rep_numattr_d = {}\n",
    "        rep_nz_d = {}\n",
    "        test_d = {}\n",
    "        for sk in sel_keys:\n",
    "            srt,pt,rr,ss,rep = sk\n",
    "            okey = (srt,'OE',rr,ss,rep)\n",
    "            avg_key = (srt,rr,ss,rep)\n",
    "            state = avgstate_d[avg_key]\n",
    "            num = numattr_d[avg_key]\n",
    "            ptirrev_df = pd.concat({'KO':irrev_d[sk],'OE':irrev_d[okey]},axis=1)\n",
    "            avg_irrev = pd.concat({'KO':(ptirrev_df.KO*state),'OE':(1-state)*ptirrev_df.OE},axis=1).sum(axis=1)\n",
    "            rep_irrev_d[int(rep)]=avg_irrev\n",
    "            rep_state_d[int(rep)]=state\n",
    "            rep_nz_d[int(rep)]=avg_irrev.index[np.where(avg_irrev>0)[0]].unique().tolist()\n",
    "            rep_numattr_d[int(rep)] = num\n",
    "            KOvOE = np.abs(irrev_d[sk]-irrev_d[okey]).loc[selg].sort_values()\n",
    "            test_d[rep]=KOvOE.index[-10:].tolist()\n",
    "            #Diff = state.loc[selg]-0.5\n",
    "            #al = 0.8 if int(rep) < 10 else 0.2\n",
    "            #plt.scatter(KOvOE,Diff,label=rep,alpha=al,color='C%d' % (int(rep)%10))\n",
    "        irrev_df=pd.DataFrame(rep_irrev_d)\n",
    "        ens_avg_irrev[(rr,ss,srt)] = irrev_df.mean(axis=1)\n",
    "        state_df = pd.DataFrame(rep_state_d)\n",
    "        ens_avg_state[(rr,ss,srt)] = state_df.mean(axis=1)\n",
    "        numattr_ser = pd.Series(rep_numattr_d)\n",
    "        ens_avg_nattr[(rr,ss,srt)] = numattr_ser\n",
    "        nz_ser = pd.Series(rep_nz_d)\n",
    "\n",
    "## this list of genes is the set that are potentially irreversible\n",
    "selg=['crp','phoB','hns','cra','fis','leuO','fnr',\n",
    "     'rhaS','gadE','rhaR','bglJ','galS','lrp',\n",
    "     'fur','rcsB','galR','stpA','arcA','gadX','fliZ',\n",
    "     'cspA','uxuR','gadW','ydeO','xylR','exuR','mlrA',\n",
    "     'fhlA','oxyR','soxS','rcsA','evgA','srlR','marR',\n",
    "     'rob','narL','adiY','dcuR','soxR','ptsG','csgD',\n",
    "     'mazE','flhC','mlc','flhD','mazF','ompR','gutM',\n",
    "     'yjjQ','marA','hdfR']\n",
    "INDS = pd.DataFrame(ens_avg_irrev).mean(axis=1).loc[selg].sort_values(ascending=False).index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39f4d8a-46d8-4885-a2c5-99a0cabf9e9f",
   "metadata": {},
   "source": [
    "## Graphml file for Fig. 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52ecf10-4ac6-472f-b569-317919e88b0c",
   "metadata": {},
   "source": [
    "### Number of genes reached in each origon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed911c37-ffcc-4c37-993e-f23e5425d969",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'input_files/generegulation_tmp.txt'\n",
    "tab = pd.read_table(fn,skiprows=11,header=None)\n",
    "cols = []\n",
    "with open(fn,'r') as fh:\n",
    "    ln = fh.readline().strip()\n",
    "    while ln.startswith('#'):\n",
    "        if ') ' in ln:\n",
    "            cols.append(ln.split(') ')[1])\n",
    "        ln = fh.readline().strip()\n",
    "tab.columns = cols\n",
    "\n",
    "df = tab\n",
    "df_sc = df.loc[:,['GENE_NAME_REGULATOR','GENE_NAME_REGULATED','GENEREGULATION_FUNCTION']]\n",
    "nodes = []\n",
    "edges = []\n",
    "sdef_edges = df_sc[df_sc.GENEREGULATION_FUNCTION.isin(['activator','repressor'])]\n",
    "G = nx.DiGraph()\n",
    "G.add_weighted_edges_from([(a,b,1 if c=='activator' else -1) for __,(a,b,c) in sdef_edges.iterrows()])\n",
    "#%%\n",
    "#sizes of strongly connected components\n",
    "sccs = sorted(nx.strongly_connected_components(G),key=len, reverse=True)\n",
    "wccs = sorted(nx.weakly_connected_components(G),key=len, reverse=True)\n",
    "len_sccs = [len(c) for c in sorted(nx.strongly_connected_components(G),key=len, reverse=True)]    \n",
    "len_wccs = [len(c) for c in sorted(nx.weakly_connected_components(G),key=len, reverse=True)] \n",
    "\n",
    "#%%\n",
    "nums_reached = {}\n",
    "nodes_reached = {}\n",
    "## find paths\n",
    "for uu in G.nodes:\n",
    "    reached = [vv for vv in G.nodes if nx.has_path(G,uu,vv)]\n",
    "    nums_reached[uu]=len(reached)\n",
    "    nodes_reached[uu]=reached\n",
    "nums_reached_ser = pd.Series(nums_reached)\n",
    "nums_reached_ser.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b311b82-b0b2-42fa-be25-8d89cf28f5be",
   "metadata": {},
   "source": [
    "### Pruning to the core network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1982990f-8dac-44e9-a1e7-00118b95c67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_network(G):\n",
    "    \"\"\"Reduces network G by pruning all nodes of zero out-degree.\"\"\"\n",
    "    simplified_nodes = []\n",
    "    for node in G.nodes:\n",
    "        in_degree = G.in_degree(node)\n",
    "        out_degree = G.out_degree(node)\n",
    "        if out_degree == 0:\n",
    "            continue\n",
    "        else:\n",
    "            simplified_nodes.append(node)\n",
    "    G_simplified = G.subgraph(simplified_nodes)\n",
    "    print(len(simplified_nodes))\n",
    "    return G_simplified\n",
    "\n",
    "## start at node that reaches the most nodes\n",
    "nd_reached_most =nums_reached_ser.idxmax() ## phoB\n",
    "reached_most = nodes_reached[nd_reached_most] + [nd_reached_most]\n",
    "G_wcc = G.subgraph(list(wccs[0])) ## largest weakly connected component\n",
    "G_reach = G.subgraph(reached_most) ## largest origon\n",
    "for ii,net in enumerate([G_reach,G_wcc]):\n",
    "    LL = 1e10\n",
    "    LLp = len(net.nodes)\n",
    "    while LL > LLp:\n",
    "        net = simplify_network(net)\n",
    "        LL = LLp\n",
    "        LLp = len(net.nodes)\n",
    "    if ii==0:\n",
    "        nx.write_gml(net,'networks/rs2.gml')\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ac0e31-ac00-47e2-87e1-1e86b8f8ddf2",
   "metadata": {},
   "source": [
    "### Generation of Fig. 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7db2b63-b5e8-4b55-b07e-25525b8b0a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnavg_irrev = pd.DataFrame(ens_avg_irrev).mean(axis=1)\n",
    "lnorm=LogNorm(vmin=1e-3,vmax=1e0)\n",
    "G_rs2 = nx.read_gml('./networks/rs2.gml')\n",
    "nodes_rs2 = list(G_rs2.nodes())\n",
    "\n",
    "nodes_all = list(gnavg_irrev.index)\n",
    "irr_all = list(gnavg_irrev.values)\n",
    "for i in nodes_rs2:\n",
    "    if i not in nodes_all:\n",
    "        nodes_all.append(i)\n",
    "        irr_all.append(0)\n",
    "overall = dict(zip(nodes_all,irr_all))\n",
    "nodecolor_d = {}\n",
    "for nd in G_rs2.nodes():\n",
    "    iprob = gnavg_irrev.loc[nd]\n",
    "    if iprob<1e-3:\n",
    "        nodecolor_d[nd]='#777777ff'\n",
    "    else:\n",
    "        num_l = my_cmap(lnorm(iprob))\n",
    "        clr_str = ''.join([str(hex(int(elt*256-1e-6)))[-2:] for elt in num_l])\n",
    "        nodecolor_d[nd]='#%s' % clr_str\n",
    "        \n",
    "nx.set_node_attributes(G_rs2, nodecolor_d, 'nodecolor')\n",
    "nx.set_node_attributes(G_rs2, dict(zip(nodes_all,nodes_all)), 'name')\n",
    "nx.write_gml(G_rs2, './networks/rs2_irr_neg2_newx.gml')\n",
    "nx.write_graphml(G_rs2, './networks/rs2_irr_neg2_newx.graphml') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d923a84-26ad-4f16-a5e8-6e185363e6a8",
   "metadata": {},
   "source": [
    "### Lower bound of the size of the set of possible rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d85ddd-45e0-4406-b870-f877adff86cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = 1\n",
    "for nd in net.nodes():\n",
    "    kplus = len(list(net.predecessors(nd)))\n",
    "    tot *= 2**(kplus-1)\n",
    "print(tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20b00c9-effe-4ab8-a977-b82ebe03c477",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log10(float(tot))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417f3ce5-516d-4c43-a543-50763c6aa516",
   "metadata": {},
   "source": [
    "## Fig. 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8927480b-4266-4295-817e-e3e54ea2e678",
   "metadata": {},
   "outputs": [],
   "source": [
    "irrev_by_insrt = pd.DataFrame(ens_avg_irrev).groupby(level=2,axis=1).mean().loc[selg]\n",
    "\n",
    "def path_weight(G,path):\n",
    "    weight = 1\n",
    "    for node in path[1:]:\n",
    "        weight *= 1/G.in_degree(node)\n",
    "    return weight\n",
    "\n",
    "def path_sign(G,path):\n",
    "    sign = 1\n",
    "    for i in range(len(path)-1):\n",
    "        edge = (path[i],path[i+1])\n",
    "        sign *= G.get_edge_data(edge[0],edge[1])['weight']\n",
    "    return sign\n",
    "    \n",
    "def num_scc_weighted(G,group):\n",
    "    sccs = list(nx.strongly_connected_components(G))\n",
    "    num_edge_scc = []\n",
    "    for n in group:  \n",
    "        num_edge = 0\n",
    "        for s in sccs:\n",
    "            if len(s) == 1 and list(G_rs2.out_edges(list(s)[0],data=True))[0][2]['weight'] == -1:\n",
    "                continue\n",
    "            if set(n) != s:\n",
    "                for n_s in s:\n",
    "                    if n_s != n:\n",
    "                        try:\n",
    "                            length=nx.shortest_path_length(G,source=n,target=n_s)\n",
    "                            if length == 0:\n",
    "                                shortest_paths = list(nx.shortest_simple_paths(G,source=n,target=n_s))\n",
    "                                if len(shortest_paths) != 1:\n",
    "                                    length = len(shortest_paths[1])\n",
    "                                else:\n",
    "                                    continue\n",
    "                            if length <= max_length:\n",
    "                                num_edge += 1/length\n",
    "                                if length == 0:\n",
    "                                    print(n,n_s)\n",
    "                                break\n",
    "                        except nx.NetworkXNoPath:\n",
    "                            continue\n",
    "        num_edge_scc.append(num_edge)\n",
    "    return num_edge_scc\n",
    "\n",
    "def num_path_scc_weighted(G,group):\n",
    "    sccs = list(nx.strongly_connected_components(G))\n",
    "    num_edge_scc = []\n",
    "    for n in group:  \n",
    "        num_edge = 0\n",
    "        for s in sccs:\n",
    "            if len(s) == 1 and list(G_rs2.out_edges(list(s)[0],data=True))[0][2]['weight'] == -1:\n",
    "                continue\n",
    "            if set(n) != s:\n",
    "                for n_s in s:\n",
    "                    if n_s != n:\n",
    "                        try:\n",
    "                            paths = list(nx.all_simple_paths(G, n, n_s, cutoff=max_length))\n",
    "                            for path in paths:\n",
    "                                weight = path_weight(G,path)\n",
    "                                sign = path_sign(G,path)\n",
    "                                num_edge += abs(weight*sign)\n",
    "                        except nx.NetworkXNoPath:\n",
    "                            continue\n",
    "        num_edge_scc.append(abs(num_edge))\n",
    "    return num_edge_scc\n",
    "\n",
    "\n",
    "max_length = 4\n",
    "\n",
    "path_scc_pos = num_path_scc_weighted(G_rs2,irrev_by_insrt.index)\n",
    "\n",
    "fig,ax_arr = plt.subplots(1,2,figsize=(3.375,2),sharey=True,sharex=True)\n",
    "for nm,col in irrev_by_insrt.items():\n",
    "    ax = ax_arr[0] if nm=='asc' else ax_arr[1]\n",
    "    title = 'Ascending' if nm=='asc' else 'Descending'\n",
    "    ax.scatter(path_scc_pos,col, c=col.values, norm=lnorm, cmap=my_cmap, alpha=0.9, s=16)\n",
    "    mm,bb = np.polyfit(np.log(np.asarray(path_scc_pos)[col>0]),np.log(col[col>0]),deg=1)\n",
    "    xvals = np.logspace(np.log10(np.amin(path_scc_pos)),np.log10(np.amax(path_scc_pos)))\n",
    "    yvals = xvals**mm * np.exp(bb)\n",
    "    rr22 = 1 - np.linalg.norm((np.asarray(path_scc_pos)[col>0])**mm*np.exp(bb)-col[col>0])/np.linalg.norm(col[col>0])\n",
    "    print(rr22)\n",
    "    ax.plot(xvals,yvals,ls=':',color='C7',alpha=0.5)\n",
    "    ax.set_xlabel('Weighted no. of paths to SCCs',fontsize=8)\n",
    "    ax.set_title(title,fontsize=8)\n",
    "    plt.setp(ax.get_xticklabels(),size=6)\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xscale('log')\n",
    "    ax.annotate('$R^2$=%.02f' % rr22, (3,4e-3),fontsize=6,fontstyle='italic')\n",
    "    for ii,txt in enumerate(irrev_by_insrt.index[:11]):\n",
    "         ax.annotate(txt,(path_scc_pos[ii],col.iloc[ii]),fontsize=6,fontstyle='italic')\n",
    "\n",
    "plt.setp(ax_arr[0].get_yticklabels(),size=6)\n",
    "ax_arr[0].set_ylabel('Irreversibility',fontsize=8)\n",
    "fig.savefig('figs/new_fig5.svg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99a904a-6c79-4d66-b84c-d57bbb485487",
   "metadata": {},
   "source": [
    "### Signficance of the trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a675a272-afc0-4576-aa4d-ff6aa0db5345",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "linregress(np.log(np.asarray(path_scc_pos)[irrev_by_insrt.asc>0]),np.log(irrev_by_insrt.asc[irrev_by_insrt.asc>0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afa9a0e-b4ff-4cc7-bc6d-a72b850e3ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "linregress(np.log(np.asarray(path_scc_pos)[irrev_by_insrt.desc>0]),np.log(irrev_by_insrt.desc[irrev_by_insrt.desc>0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c61666-296b-4096-b0c2-43c5f34369f3",
   "metadata": {},
   "source": [
    "## Fig. 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37c9a1c-2379-46d9-aad5-12154749700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cmap = copy(mpl.colormaps['Spectral_r']) # copy the default cmap\n",
    "my_cmap.set_bad('C7')\n",
    "my_cmap.set_under('w')\n",
    "\n",
    "MIN_OFF = 1e-6\n",
    "def irr_imshow(ax,data,inds,plot_xlabels=False,plot_ylabels=False,xlbl='',ylbl='',xtls=[]):\n",
    "    im = ax.imshow(data.loc[inds]+MIN_OFF,norm=lnorm,cmap=my_cmap)\n",
    "    ax.set_yticks(np.arange(len(inds)))\n",
    "    ax.set_xticks(np.arange(6))\n",
    "    if plot_ylabels:\n",
    "        ax.set_yticklabels(['%s' % ind for ind in inds],size=5,fontstyle='italic')\n",
    "        ax.set_ylabel(ylbl,size=6)\n",
    "    if plot_xlabels:\n",
    "        ax.set_xticklabels(xtls,size=5,rotation=90,horizontalalignment='center')\n",
    "        ax.set_xlabel(xlbl,size=6)\n",
    "    return im,ax\n",
    "    \n",
    "CUT1 = DF[DF.loc[:,2]=='0.00']\n",
    "CUT2 = DF[(DF.loc[:,3]=='1.00')|((DF.loc[:,3]=='0.00') & (DF.loc[:,2]=='0.00'))]\n",
    "CUT3 = DF[(DF.loc[:,2].astype(float)+DF.loc[:,3].astype(float)==1)|((DF.loc[:,3]=='0.00')&(DF.loc[:,2]=='0.00'))]\n",
    "\n",
    "inds_l = np.split(INDS.get_level_values(0),[25])\n",
    "for iii,inds in enumerate(inds_l):\n",
    "    lnorm=LogNorm(vmin=1e-2,vmax=1e0) if iii==0 else LogNorm(vmin=1e-3,vmax=1e0)    \n",
    "    fig,ax_arr = plt.subplots(4,3,figsize=(2.25,10),sharex=True,sharey=True)\n",
    "    for jj,CUT in enumerate([CUT1,CUT2,CUT3]):\n",
    "        repavg_l = []\n",
    "        for kw,grp in CUT.groupby([0,1,2,3]):\n",
    "            sel_keys = [tuple(row.values) for dum,row in grp.iterrows()]\n",
    "            sel_d = {}\n",
    "            for ii in range(len(sel_keys)):\n",
    "                if jj<1:\n",
    "                    sel_d[(sel_keys[ii][0],sel_keys[ii][1],sel_keys[ii][3],int(sel_keys[ii][4]))]=irrev_d[sel_keys[ii]]\n",
    "                else:\n",
    "                    if sel_keys[ii][3]=='0.00':\n",
    "                        sel_d[(sel_keys[ii][0],sel_keys[ii][1],'1.00',int(sel_keys[ii][4]))]=irrev_d[sel_keys[ii]]\n",
    "                    else:\n",
    "                        sel_d[(sel_keys[ii][0],sel_keys[ii][1],sel_keys[ii][2],int(sel_keys[ii][4]))]=irrev_d[sel_keys[ii]]                    \n",
    "                \n",
    "            repavg_irrev = pd.DataFrame(sel_d).groupby(level=[0,1,2],axis=1).mean()\n",
    "            repavg_l.append(repavg_irrev)\n",
    "        cut_data = pd.concat(repavg_l,axis=1).loc[selg]\n",
    "        vals = cut_data.loc[inds].values.ravel()\n",
    "\n",
    "        for kk,srt in enumerate(['asc','desc']):\n",
    "            for ll,pt in enumerate(['KO','OE']):\n",
    "                ROW = kk*2 +ll\n",
    "                ax = ax_arr[ROW,jj]\n",
    "                plot_data = cut_data.xs((srt,pt),level=[0,1],axis=1).loc[inds]\n",
    "                rev_srt_ord = True if jj<1 else False\n",
    "                srt_cols = sorted(plot_data.columns,key=lambda x: float(x),reverse=rev_srt_ord)\n",
    "                if jj==0:\n",
    "                    pylbl = True\n",
    "                    srtlbl = 'Asc.' if srt=='asc' else 'Desc.'\n",
    "                    ylbl = 'Gene, Pert: %s, Sort: %s ' % (pt,srtlbl)\n",
    "                else:\n",
    "                    pylbl = False\n",
    "                    ylbl = ''\n",
    "                if ROW==3:\n",
    "                    pxlbl = True\n",
    "                    xtls = srt_cols\n",
    "                    if jj==0:\n",
    "                        xlbl='r, s=0'\n",
    "                    elif jj==1:\n",
    "                        xlbl='s, r=1'\n",
    "                    else:\n",
    "                        xlbl = 's, r=1-s'\n",
    "                else:\n",
    "                    pxlbl = False\n",
    "                    xlbl = ''\n",
    "                img,ax = irr_imshow(ax,plot_data.loc[:,srt_cols],inds,plot_xlabels=pxlbl,plot_ylabels=pylbl,xlbl=xlbl,ylbl=ylbl,xtls=xtls)\n",
    "    fig.subplots_adjust(top=0.925)\n",
    "    PTS = ax.get_position().get_points()\n",
    "    bttm = PTS[0,1]\n",
    "    tp = PTS[1,1]\n",
    "    cbax = fig.add_subplot([0.15,0.93,0.73,0.01])\n",
    "    cbar = fig.colorbar(img,cax=cbax,orientation='horizontal')\n",
    "    cbar.ax.xaxis.set_ticks_position('top')\n",
    "    cbar.ax.xaxis.set_label_position('top')\n",
    "    cbar.set_label('Irreversibility',size=8)\n",
    "    plt.setp(cbar.ax.xaxis.get_ticklabels(),size=6)\n",
    "    torblbl = 'top_genes' if iii==0 else 'bottom_genes'\n",
    "    fig.savefig('figs/irreversibility_by_case_%s.svg' % torblbl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f241a9-26d8-4a35-b11b-923f7eb101a6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Fig. 3 (Properties of the rules as a function of $r$ and $s$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226bc659-8d77-4d48-96aa-7a3a987d3942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy\n",
    "from sympy.abc import r,s\n",
    "from sympy.logic.boolalg import truth_table\n",
    "from collections import defaultdict\n",
    "\n",
    "def generate_possible_rules_probabilities_new(unas,expr='',prob=1,paren=0):\n",
    "    if len(unas)==1:\n",
    "        ## termination condition\n",
    "        expr+=  ('%s '% (unas[0])) +')'*paren\n",
    "        return [([],expr,prob,0)]\n",
    "    nexpr1 = expr + ' %s & ( ' % (unas[0])\n",
    "    nprob1 = prob*r\n",
    "    nparen1 = paren + 1\n",
    "    nexpr21 = expr + ' %s | ' % (unas[0])\n",
    "    nprob21 = prob*(1-r)*s\n",
    "    nparen21 = paren\n",
    "    nexpr221 = expr + ' %s & ' % (unas[0])\n",
    "    nprob221 = prob*(1-r)*(1-s)\n",
    "    nparen221 = paren\n",
    "    return generate_possible_rules_probabilities_new(unas[1:],nexpr1,nprob1,nparen1)+ \\\n",
    "           generate_possible_rules_probabilities_new(unas[1:],nexpr21,nprob21,nparen21) + \\\n",
    "           generate_possible_rules_probabilities_new(unas[1:],nexpr221,nprob221,nparen221)\n",
    "\n",
    "def parse_rule_attrs(rstr, ch='a'):\n",
    "    L = rstr.split('%s_' % ch)\n",
    "    cd = 1\n",
    "    cd_d = defaultdict(list)\n",
    "    inp_l = []\n",
    "    for elt in L:\n",
    "        if elt=='': ## string starts with no parentheses\n",
    "            continue\n",
    "        elif elt.startswith('('): ## string starts with parentheses (at most 1)\n",
    "            cd+=1\n",
    "        elif '& (' in elt:\n",
    "            inp_l.append(elt.split(' &')[0])\n",
    "            cd_d[cd].extend(inp_l)\n",
    "            inp_l=[]\n",
    "            cd += elt.count('(')\n",
    "        elif ') | (' in elt:\n",
    "            inp_l.append(elt.split(')')[0])\n",
    "            cd_d[cd].extend(inp_l)\n",
    "            inp_l=[]\n",
    "        elif '| (' in elt:\n",
    "            inp_l.append(elt.split(' |')[0])\n",
    "            cd_d[cd].extend(inp_l)\n",
    "            inp_l=[]\n",
    "            cd +=2\n",
    "        elif ' | ' in elt: ## this case MUST COME AFTER ') | ('\n",
    "            ## inp_l will always be empty in this case\n",
    "            inp_l.append(elt.split(' | ')[0])\n",
    "            cd_d[cd].extend(inp_l)\n",
    "            inp_l=[]\n",
    "        elif ' & ' in elt:\n",
    "            inp_l.append(elt.split(' & ')[0])\n",
    "        elif elt.endswith(')'): ## last term\n",
    "            inp_l.append(elt.split(')')[0])\n",
    "            cd_d[cd].extend(inp_l)\n",
    "            inp_l=[]\n",
    "        else:\n",
    "            inp_l.append(elt)\n",
    "            cd_d[cd].extend(inp_l)\n",
    "            inp_l=[]\n",
    "    return dict(cd_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ebeef8-3b42-4f29-8ec0-67725aa769aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate the possible rules for networks up to size 7\n",
    "\n",
    "myexpr_l = []\n",
    "bias_poly_l = []\n",
    "for tsz in range(2,8):\n",
    "    print(tsz)\n",
    "    avec = sympy.symarray(a,tsz)\n",
    "    __,RULES,PROBS,__ = zip(*generate_possible_rules_probabilities_new(avec.tolist(),expr='',prob=1,paren=0))\n",
    "    sympRULES = [sympy.sympify(RR) for RR in RULES]\n",
    "    rule_cats = pd.Categorical([str(RR) for RR in sympRULES])\n",
    "    unique_rules = rule_cats.value_counts().index\n",
    "    rule_prob_l = []\n",
    "    for RR in unique_rules:\n",
    "        cd_d = parse_rule_attrs(RR)\n",
    "        TF = rule_cats==RR\n",
    "        cPROB = 0\n",
    "        for ii in range(len(PROBS)):\n",
    "            if TF[ii]:\n",
    "                cPROB+=PROBS[ii]\n",
    "                \n",
    "        rule_prob_l.append((RR,sympy.simplify(cPROB),cd_d))\n",
    "    myexpr=0\n",
    "    bias_l = []\n",
    "    for expr,prob,cd_d in rule_prob_l:\n",
    "        TT_df = pd.DataFrame([np.r_[bvars,op==sympy.true] for bvars,op in truth_table(expr,avec)])\n",
    "        bias = TT_df.iloc[:,-1].sum()\n",
    "        bias_l.append(bias*prob)\n",
    "        ## code to calculate the average canalizing depth\n",
    "        wt_sum = 0\n",
    "        totL = 0\n",
    "        for kk,vv in cd_d.items():\n",
    "            wt_sum += kk*len(vv)\n",
    "            totL+=len(vv)\n",
    "        myexpr+=prob*sympy.Rational(wt_sum,totL) ## this now gives the expected canalizing depth\n",
    "    bias_poly_l.append(sum(bias_l))\n",
    "    myexpr_l.append(myexpr)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3423dfba-a55d-464b-9255-6de6402f65a0",
   "metadata": {},
   "source": [
    "#### GENERATE CODE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48918d04-2db9-460e-b12c-5d35a9e07a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import pycode\n",
    "for ii,expr in enumerate(myexpr_l):\n",
    "    print(\"def ex_cdepth%d(r,s):\\n    return %s\"% (ii+2,sympy.simplify(expr)))\n",
    "    print(\"\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "for ii,bias in enumerate(bias_poly_l):\n",
    "    print(\"def ex_bias%d(r,s):\\n    return %s\"% (ii+2,sympy.simplify(bias)))\n",
    "    print(\"\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76ed8dc-abdd-4dda-90c7-8555ee6fddcb",
   "metadata": {},
   "source": [
    "#### Paste code into cell below to define the polynomial functions for plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a091174-8108-4bd8-b537-53c8de275b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ex_cdepth2(r,s):\n",
    "    return 1\n",
    "\n",
    "def ex_cdepth3(r,s):\n",
    "    return -8*r**2*s**2/3 + 2*r**2*s/3 + 16*r*s**2/3 - 10*r*s/3 - 8*s**2/3 + 8*s/3 + 1\n",
    "\n",
    "def ex_cdepth4(r,s):\n",
    "    return -r**3*s**3 + 3*r**3*s**2/4 + r**3*s/4 + 3*r**2*s**3 - 13*r**2*s**2/2 - \\\n",
    "           r**2*s/4 - 3*r*s**3 + 43*r*s**2/4 - 4*r*s + s**3 - 5*s**2 + 4*s + 1\n",
    "\n",
    "def ex_cdepth5(r,s):\n",
    "    return 2*r**4*s**3/5 - 2*r**4*s/5 - 16*r**3*s**3/5 + 8*r**3*s**2/5 + 8*r**3*s/5 + \\\n",
    "           36*r**2*s**3/5 - 52*r**2*s**2/5 - 11*r**2*s/5 - 32*r*s**3/5 + 16*r*s**2 - \\\n",
    "           21*r*s/5 + 2*s**3 - 36*s**2/5 + 26*s/5 + 1\n",
    "\n",
    "def ex_cdepth6(r,s):\n",
    "    return r**5*s**4/6 + r**5*s**3/6 - 5*r**5*s**2/6 + r**5*s/2 - 5*r**4*s**4/3 + \\\n",
    "           13*r**4*s**3/6 + 13*r**4*s**2/6 - 8*r**4*s/3 + 5*r**3*s**4 - 25*r**3*s**3/2 + \\\n",
    "           2*r**3*s**2 + 11*r**3*s/2 - 20*r**2*s**4/3 + 137*r**2*s**3/6 - 35*r**2*s**2/2 - \\\n",
    "           17*r**2*s/3 + 25*r*s**4/6 - 53*r*s**3/3 + 49*r*s**2/2 - 4*r*s - s**4 + 5*s**3 - \\\n",
    "           31*s**2/3 + 19*s/3 + 1\n",
    "\n",
    "def ex_cdepth7(r,s):\n",
    "    return -r**6*s**6 + 19*r**6*s**5/7 - 17*r**6*s**4/7 + r**6*s**3/7 + 8*r**6*s**2/7 - \\\n",
    "           4*r**6*s/7 + 6*r**5*s**6 - 123*r**5*s**5/7 + 130*r**5*s**4/7 - 33*r**5*s**3/7 - \\\n",
    "           6*r**5*s**2 + 26*r**5*s/7 - 15*r**4*s**6 + 330*r**4*s**5/7 - 58*r**4*s**4 + \\\n",
    "           187*r**4*s**3/7 + 64*r**4*s**2/7 - 10*r**4*s + 20*r**3*s**6 - 470*r**3*s**5/7 + \\\n",
    "           664*r**3*s**4/7 - 457*r**3*s**3/7 + 25*r**3*s**2/7 + 14*r**3*s - 15*r**2*s**6 + \\\n",
    "           375*r**2*s**5/7 - 601*r**2*s**4/7 + 564*r**2*s**3/7 - 215*r**2*s**2/7 - 78*r**2*s/7 + \\\n",
    "           6*r*s**6 - 159*r*s**5/7 + 286*r*s**4/7 - 346*r*s**3/7 + 261*r*s**2/7 - 24*r*s/7 - \\\n",
    "           s**6 + 4*s**5 - 8*s**4 + 12*s**3 - 101*s**2/7 + 52*s/7 + 1\n",
    "\n",
    "def ex_bias2(r,s):\n",
    "    return -2*r*s + 2*s + 1\n",
    "\n",
    "def ex_bias3(r,s):\n",
    "    return -2*r**2*s**2 + 2*r**2*s + 4*r*s**2 - 10*r*s - 2*s**2 + 8*s + 1\n",
    "\n",
    "def ex_bias4(r,s):\n",
    "    return 4*r**3*s**2 - 4*r**3*s - 16*r**2*s**2 + 16*r**2*s + 20*r*s**2 - 34*r*s - 8*s**2 + 22*s + 1\n",
    "\n",
    "def ex_bias5(r,s):\n",
    "    return 4*r**4*s**4 - 12*r**4*s**2 + 8*r**4*s - 16*r**3*s**4 + 8*r**3*s**3 + 48*r**3*s**2 -\\\n",
    "           40*r**3*s + 24*r**2*s**4 - 24*r**2*s**3 - 78*r**2*s**2 + 78*r**2*s - 16*r*s**4 + \\\n",
    "           24*r*s**3 + 60*r*s**2 - 98*r*s + 4*s**4 - 8*s**3 - 18*s**2 + 52*s + 1\n",
    "\n",
    "def ex_bias6(r,s):\n",
    "    return 8*r**5*s**5 - 16*r**5*s**4 - 8*r**5*s**3 + 32*r**5*s**2 - 16*r**5*s - 40*r**4*s**5 + \\\n",
    "           108*r**4*s**4 - 164*r**4*s**2 + 96*r**4*s + 80*r**3*s**5 - 272*r**3*s**4 + 112*r**3*s**3 + \\\n",
    "           316*r**3*s**2 - 236*r**3*s - 80*r**2*s**5 + 328*r**2*s**4 - 256*r**2*s**3 - 292*r**2*s**2 + \\\n",
    "           300*r**2*s + 40*r*s**5 - 192*r*s**4 + 216*r*s**3 + 132*r*s**2 - 258*r*s - 8*s**5 + 44*s**4 - \\\n",
    "           64*s**3 - 24*s**2 + 114*s + 1\n",
    "\n",
    "def ex_bias7(r,s):\n",
    "    return 8*r**6*s**6 - 40*r**6*s**5 + 40*r**6*s**4 + 40*r**6*s**3 - 80*r**6*s**2 + 32*r**6*s - \\\n",
    "           48*r**5*s**6 + 280*r**5*s**5 - 368*r**5*s**4 - 136*r**5*s**3 + 496*r**5*s**2 - 224*r**5*s + \\\n",
    "           120*r**4*s**6 - 800*r**4*s**5 + 1328*r**4*s**4 - 72*r**4*s**3 - 1240*r**4*s**2 + 664*r**4*s - \\\n",
    "           160*r**3*s**6 + 1200*r**3*s**5 - 2432*r**3*s**4 + 936*r**3*s**3 + 1528*r**3*s**2 - 1072*r**3*s + \\\n",
    "           120*r**2*s**6 - 1000*r**2*s**5 + 2408*r**2*s**4 - 1616*r**2*s**3 - 914*r**2*s**2 + 1002*r**2*s - \\\n",
    "           48*r*s**6 + 440*r*s**5 - 1232*r*s**4 + 1152*r*s**3 + 204*r*s**2 - 642*r*s + 8*s**6 - 80*s**5 + \\\n",
    "           256*s**4 - 304*s**3 + 6*s**2 + 240*s + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4804abb-f093-4ad6-98eb-c7a4cddfff62",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Contour plots as a funciton of $r$ and $s$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee85463-beaa-4f4b-9719-5c3db0dd409e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['svg.fonttype']='none'\n",
    "plt.rcParams['text.usetex']=True\n",
    "plt.rcParams['font.family']='serif'\n",
    "rvals = np.linspace(0,1)\n",
    "svals = np.linspace(0,1)\n",
    "vvals1 = np.linspace(0, 1, 11, endpoint=True)\n",
    "vvals2 = np.linspace(0.14, 0.56, 8, endpoint=True)\n",
    "RR,SS = np.meshgrid(rvals,svals)\n",
    "func_array = np.asarray([#[ex_bias2,ex_cdepth2],\n",
    "                         [ex_bias3,ex_cdepth3],\n",
    "                         [ex_bias4,ex_cdepth4],\n",
    "                         [ex_bias5,ex_cdepth5],\n",
    "                         [ex_bias6,ex_cdepth6],\n",
    "                         [ex_bias7,ex_cdepth7],\n",
    "                        ]).T\n",
    "fig,ax_arr = plt.subplots(func_array.shape[0],func_array.shape[1],sharex=True,sharey=True,figsize=(6.5,3))\n",
    "for ii,frow in enumerate(func_array):\n",
    "    for jj,ff in enumerate(frow):\n",
    "        #vm,vM = (0,1) #if jj==0 else ()\n",
    "        BB = ff(RR,SS)\n",
    "        if not isinstance(BB,np.ndarray):\n",
    "            BB = np.ones(RR.shape)\n",
    "        DENOM = 2**(jj+3) if ii==0 else (jj+3)\n",
    "        vvals = vvals1 if ii==0 else vvals2\n",
    "        cplot = ax_arr[ii,jj].contourf(RR,SS,BB/DENOM,vvals)\n",
    "        if jj==0:\n",
    "            plt.setp(ax_arr[ii,jj].get_yticklabels(),size=6)\n",
    "        elif jj==func_array.shape[1]-1:\n",
    "            lbl = 'Bias' if ii==0 else 'Avg. canalization depth'\n",
    "            cbar=fig.colorbar(cplot,ax=ax_arr[ii,jj])\n",
    "            cbar.set_label(lbl,size=7)\n",
    "            plt.setp(cbar.ax.yaxis.get_ticklabels(),size=6)\n",
    "        if ii==func_array.shape[0]-1:\n",
    "            plt.setp(ax_arr[ii,jj].get_xticklabels(),size=6)\n",
    "        elif ii==0:\n",
    "            ax_arr[ii,jj].set_title('N=%d' % (jj+3),size=8)\n",
    "\n",
    "for ii in range(func_array.shape[0]):\n",
    "    ax_arr[ii,0].set_ylabel(r'$s$: P($y_i+y_{i+1}$)',size=7)\n",
    "for ii in range(func_array.shape[1]):\n",
    "    ax_arr[-1,ii].set_xlabel(r'$r$: P($y_i\\times(y_{i+1}$ )',size=7)\n",
    "    # if ii==0:\n",
    "    #     ax_arr[0,ii].set_title('Bias',size=8)\n",
    "    # else:\n",
    "    #     ax_arr[0,ii].set_title('Avg. canalization depth',size=8)\n",
    "#cb = plt.colorbar()\n",
    "#cb.set_label('Avg. canalization depth')\n",
    "fig.savefig('figs/network_contours.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ad1a43-4b7a-44b7-8f41-e52b798dfa70",
   "metadata": {},
   "source": [
    "## Fig. S1: \n",
    "Convergence of irreversibility estimated from independent sets of realizations.\n",
    "\n",
    "_These cells require the script_ `analyze_replicates.py` _to be run_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3669e7d-46c3-4d62-86f0-668a5f31674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ovr_out_d = pd.read_pickle('tmp/overall_output_d.pkl')\n",
    "keyDF = pd.DataFrame(ovr_out_d.keys(),columns=['s','r','srt','N','quant','stat'])\n",
    "statGB = keyDF.groupby(['s','r','srt'])\n",
    "def ss2bxp(ss):\n",
    "    # med: Median (scalar).\n",
    "    # q1, q3: First & third quartiles (scalars).\n",
    "    # whislo, whishi: Lower & upper whisker positions (scalars).\n",
    "    # mean: Mean (scalar). Needed if showmeans=True.    \n",
    "    bxp_stat_d = {}\n",
    "    bxp_stat_d['med'] = ss.loc['50%']\n",
    "    bxp_stat_d['q1'] = ss.loc['25%']\n",
    "    bxp_stat_d['q3'] = ss.loc['75%']\n",
    "    bxp_stat_d['whislo'] = ss.loc['min']\n",
    "    bxp_stat_d['whishi'] = ss.loc['max']\n",
    "    bxp_stat_d['mean'] = ss.loc['mean']\n",
    "    return bxp_stat_d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4686640e-e716-4f73-a007-d76b7ad7debb",
   "metadata": {},
   "source": [
    "### Fig. S1A:\n",
    "Ascending results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbe7410-05ce-4dc4-aae7-33a4d85d51fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncol = 4\n",
    "plt.rcParams['svg.fonttype']='none'\n",
    "plt.rcParams['text.usetex']=False\n",
    "plt.rcParams['font.family']='serif'\n",
    "\n",
    "fig,ax_arr = plt.subplots(3,ncol,figsize=(7.5,5),dpi=200,sharey=True,sharex=True)\n",
    "sel_srt = 'asc'\n",
    "fig_suptitle = 'Input sorting: Ascending'\n",
    "for (ss,rr,srt),grp in statGB:\n",
    "    if srt!=sel_srt:\n",
    "        continue\n",
    "    if ss=='1.00':\n",
    "        ax_row = 2\n",
    "        ax_col = int((float(rr)+1e-12)/0.20)-1\n",
    "    elif float(ss) + float(rr)==1:\n",
    "        ax_row = 1\n",
    "        ax_col = int((float(rr)+1e-12)/0.20)-1\n",
    "    else:\n",
    "        ax_row = 0\n",
    "        ax_col = ncol-int((float(ss)+1e-12)/0.20)\n",
    "        ax_l = [ax_arr[ax_row,ax_col]]\n",
    "    for quant,grp2 in grp.groupby('quant'):\n",
    "        if quant !='irrev':\n",
    "            continue\n",
    "        for stat,grp3 in grp2.groupby('stat'):\n",
    "            if stat != 'rmsd':\n",
    "                continue\n",
    "            else:\n",
    "                ylbl = 'Irreversibility RMSD'\n",
    "            dod = {}\n",
    "            for nn,row in grp3.iterrows():\n",
    "                kk = tuple(row.values)\n",
    "                dod[row.N] = ss2bxp(ovr_out_d[kk])\n",
    "            bxp_l = [dod[ii] for ii in range(1,11)]\n",
    "            pos_l = range(1,11)\n",
    "            #for axnum,ax in enumerate(ax_l):\n",
    "            ax = ax_arr[ax_row,ax_col]\n",
    "            ax.bxp(bxp_l,pos_l,0.7,showmeans=False,showfliers=False)\n",
    "            if (ax_row==2):\n",
    "                ax.set_xlabel('Realizations in set',size=8)\n",
    "                plt.setp(ax.get_xticklabels(),size=6)\n",
    "            if ax_col==0:\n",
    "                ax.set_ylabel(ylbl,size=8)\n",
    "                plt.setp(ax.get_yticklabels(),size=6)\n",
    "            ax.set_title(f's:{ss} r:{rr}',size=6)\n",
    "            \n",
    "fig.suptitle(fig_suptitle)\n",
    "fig.savefig('figs/rmsd_convergence_ascending.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32691e57-b166-4343-8cbb-b48c536057e9",
   "metadata": {},
   "source": [
    "### Fig. S1B\n",
    "Descending results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78f11f8-4394-4bf1-9a26-24ea887f9656",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax_arr = plt.subplots(3,ncol,figsize=(7.5,5),dpi=200,sharey=True,sharex=True)\n",
    "sel_srt = 'desc'\n",
    "fig_suptitle = 'Input sorting: Descending'\n",
    "\n",
    "for (ss,rr,srt),grp in statGB:\n",
    "    if srt!=sel_srt:\n",
    "        continue\n",
    "    if ss=='1.00':\n",
    "        ax_row = 2\n",
    "        ax_col = int((float(rr)+1e-12)/0.20)-1\n",
    "    elif float(ss) + float(rr)==1:\n",
    "        ax_row = 1\n",
    "        ax_col = int((float(rr)+1e-12)/0.20)-1\n",
    "    else:\n",
    "        ax_row = 0\n",
    "        ax_col = ncol-int((float(ss)+1e-12)/0.20)\n",
    "        ax_l = [ax_arr[ax_row,ax_col]]\n",
    "    for quant,grp2 in grp.groupby('quant'):\n",
    "        if quant !='irrev':\n",
    "            continue\n",
    "        for stat,grp3 in grp2.groupby('stat'):\n",
    "            if stat != 'rmsd':\n",
    "                continue\n",
    "            else:\n",
    "                ylbl = 'Irreversibility RMSD'\n",
    "            dod = {}\n",
    "            for nn,row in grp3.iterrows():\n",
    "                kk = tuple(row.values)\n",
    "                dod[row.N] = ss2bxp(ovr_out_d[kk])\n",
    "            bxp_l = [dod[ii] for ii in range(1,11)]\n",
    "            pos_l = range(1,11)\n",
    "            #for axnum,ax in enumerate(ax_l):\n",
    "            ax = ax_arr[ax_row,ax_col]\n",
    "            ax.bxp(bxp_l,pos_l,0.7,showmeans=False,showfliers=False)\n",
    "            if (ax_row==2):\n",
    "                ax.set_xlabel('Realizations in set',size=8)\n",
    "                plt.setp(ax.get_xticklabels(),size=6)\n",
    "            if ax_col==0:\n",
    "                ax.set_ylabel(ylbl,size=8)\n",
    "                plt.setp(ax.get_yticklabels(),size=6)\n",
    "            ax.set_title(f's:{ss} r:{rr}',size=6)\n",
    "\n",
    "fig.suptitle(fig_suptitle)\n",
    "fig.savefig('figs/rmsd_convergence_descending.svg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
